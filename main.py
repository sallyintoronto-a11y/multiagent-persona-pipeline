# -*- coding: utf-8 -*-
"""main

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1b5IwLBRccwuk_47gNIFLuOYYdHjAxTEX
"""

# ============================================================
# Graph Workflow (Types, Helpers, Subgraphs, Supervisor)
# ============================================================
# --- Types ---
class AgentOutputDict(TypedDict):
    agent_id: str
    image_refs: List[str]
    visual_description: str
    interpretation: str
    cultural_or_ethical_reflection: str
    reasoning: str

class GraphState(TypedDict, total=False):
    image_path: str
    history: List[Dict[str, Any]]
    pair_results: List[Dict[str, Any]]
    final_report: Dict[str, Any]

# --- Image + LLM Helpers ---
def image_content_from_path(path: str) -> Dict[str, Any]:
    """Return a Chat Completions 'image_url' content block from a local file path."""
    if not os.path.exists(path):
        raise FileNotFoundError(f"Image not found: {path}")
    if not os.path.isfile(path):
        raise ValueError(f"Not a file: {path}")

    mime = mimetypes.guess_type(path)[0] or "image/png"
    with open(path, "rb") as f:
        b64 = base64.b64encode(f.read()).decode("utf-8")
    data_url = f"data:{mime};base64,{b64}"
    return {"type": "image_url", "image_url": {"url": data_url}}

def _safe_json_parse(s: str):
    s = s.strip()
    try:
        return json.loads(s)
    except Exception:
        m = re.search(r"\{.*\}", s, re.DOTALL)
        if m:
            return json.loads(m.group(0))
        raise

def call_mm_llm_agent(system_prompt: str, image_path: str) -> AgentOutputDict:
    """LangChain ChatOpenAI (VISION_MODEL) — image + text → JSON object."""
    img_block = image_content_from_path(image_path)
    user_payload = [
        {"type": "text", "text": f"[IMAGE]: {os.path.basename(image_path)}"},
        img_block
    ]
    msgs = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=user_payload),
    ]
    resp = vision_llm.invoke(msgs)  # AIMessage

    out = _safe_json_parse(resp.content)
    out["image_refs"] = [os.path.basename(image_path)]  # filename only
    return out

def call_llm_score_pair_3(
    system_prompt: str,
    user_prompt: str,
    pair_key: str,
    agentA_id: str,
    agentB_id: str
) -> Dict[str, Any]:
    msgs = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=user_prompt),
    ]
    resp = scorer_llm.invoke(msgs)

    parsed = _safe_json_parse(resp.content)
    parsed.setdefault("pair", pair_key)
    agents = parsed.setdefault("agents", {})
    for aid in (agentA_id, agentB_id):
        agents.setdefault(aid, {
            "factuality": 0,
            "norm_appropriateness": 0,
            "bias_presence": 0,
            "notes": []
        })
    parsed.setdefault("delta", {
        "factuality": agents[agentA_id]["factuality"] - agents[agentB_id]["factuality"],
        "norm_appropriateness": agents[agentA_id]["norm_appropriateness"] - agents[agentB_id]["norm_appropriateness"],
        "bias_presence": agents[agentA_id]["bias_presence"] - agents[agentB_id]["bias_presence"],
    })
    return parsed


# --- Pair Subgraph (two agents + supervisor) ---
def build_pair_subgraph(pair_key: str, personas_by_id: Dict[str, Dict[str, Any]]):
    sg = StateGraph(GraphState)

    a_id, b_id = PERSONAS["pair_index"][pair_key]
    A = personas_by_id[a_id]
    B = personas_by_id[b_id]

    def node_agent_A(state: GraphState) -> GraphState:
        sysA = build_persona_system_prompt(A, state["image_path"])
        outA = call_mm_llm_agent(sysA, state["image_path"])
        outA["agent_id"] = A["id"]
        rec = {"node": f"{pair_key}:A", "output": outA}
        return {"history": state.get("history", []) + [rec], "image_path": state["image_path"]}

    def node_agent_B(state: GraphState) -> GraphState:
        sysB = build_persona_system_prompt(B, state["image_path"])
        outB = call_mm_llm_agent(sysB, state["image_path"])
        outB["agent_id"] = B["id"]
        rec = {"node": f"{pair_key}:B", "output": outB}
        return {"history": state.get("history", []) + [rec], "image_path": state["image_path"]}

    def node_pair_supervisor(state: GraphState) -> GraphState:
        pair_hist = [h for h in state.get("history", []) if h["node"].startswith(pair_key + ":")]
        if len(pair_hist) < 2:
            raise RuntimeError(f"Pair {pair_key}: missing agent outputs")

        outA = pair_hist[-2]["output"]
        outB = pair_hist[-1]["output"]

        sys = build_pair_scorer_system_prompt_3(
            pair_key=pair_key,
            agentA_id=outA.get("agent_id", "A"),
            agentB_id=outB.get("agent_id", "B"),
        )
        usr = build_pair_scorer_user_prompt(outA, outB)
        scored = call_llm_score_pair_3(
            sys, usr, pair_key, outA.get("agent_id", "A"), outB.get("agent_id", "B")
        )

        # Wrap with evaluation key + include both agents' original outputs
        pair_entry = {
            "pair": scored.get("pair", pair_key),
            "evaluation": {
                "agents": scored.get("agents", {}),
                "delta": scored.get("delta", {})
            },
            "agent_outputs": {
                outA.get("agent_id", "A"): outA,
                outB.get("agent_id", "B"): outB,
            }
        }

        return {
            "pair_results": state.get("pair_results", []) + [pair_entry],
            "history": state.get("history", [])
        }

    sg.add_node("agent_A", node_agent_A)
    sg.add_node("agent_B", node_agent_B)
    sg.add_node("pair_supervisor", node_pair_supervisor)

    sg.add_edge(START, "agent_A")
    sg.add_edge("agent_A", "agent_B")
    sg.add_edge("agent_B", "pair_supervisor")
    sg.add_edge("pair_supervisor", END)

    return sg.compile()

# --- Top-level Supervisor Graph ---
def create_workflow(selected_pairs: Optional[List[str]] = None):
    personas = PERSONAS["personas"]
    personas_by_id = {p["id"]: p for p in personas}

    if selected_pairs is None:
        selected_pairs = list(PERSONAS["pair_index"].keys())

    subgraphs = {pair: build_pair_subgraph(pair, personas_by_id) for pair in selected_pairs}

    g = StateGraph(GraphState)

    def node_supervisor(state: GraphState) -> Command:
        done = len(state.get("pair_results", []))
        if done >= len(selected_pairs):
            return Command(goto="finalize", update=state)
        next_pair = selected_pairs[done]
        return Command(goto=next_pair, update=state)

    def node_finalize(state: GraphState) -> GraphState:
        final = {
            "image_path": state.get("image_path"),
            "pairs": state.get("pair_results", []),
            "schemas": {"eval_axes": EVAL_SCHEMA_3, "personas_note": PERSONAS["schema_note"]}
        }
        return {"final_report": final}

    g.add_node("supervisor", node_supervisor)
    for pair, subg in subgraphs.items():
        g.add_node(pair, subg)
    g.add_node("finalize", node_finalize)

    g.add_edge(START, "supervisor")
    for pair in selected_pairs:
        g.add_edge(pair, "supervisor")
    g.add_edge("supervisor", END)

    return g.compile()